{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\ML_temp\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\user\\anaconda3\\envs\\ML_temp\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\user\\anaconda3\\envs\\ML_temp\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\user\\anaconda3\\envs\\ML_temp\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\user\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ff8031329242eeb00494d6026b173d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/5.97M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38e81e5742443c3977c84ade64ea3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/134k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\AI_class_yang\\AI_code\\  \\body_part_measurement_source\\backend\\bus.jpg: 640x480 4 persons, 18.0ms\n",
      "Speed: 7.0ms preprocess, 18.0ms inference, 35.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolo11n-pose.pt\")  # load an official model\n",
    "# 전역 변수\n",
    "frame = None  # 웹캠에서 캡처한 프레임\n",
    "captured_frames = []  # 캡처된 프레임 저장\n",
    "lock = threading.Lock()\n",
    "\n",
    "# 키포인트 인덱스\n",
    "KEYPOINTS_TO_CHECK = [0, 5, 6, 7, 8, 9, 10]  # 머리(0), 왼쪽 어깨(5), 오른쪽 어깨(6), 팔/다리(7-10)\n",
    "\n",
    "# Predict with the model\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹캠 캡처 함수\n",
    "def capture_webcam():\n",
    "    global frame\n",
    "    cap = cv2.VideoCapture(0)  # 0번 웹캠\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        with lock:\n",
    "            frame = img\n",
    "    cap.release()\n",
    "\n",
    "# YOLO Pose로 사람 감지 및 조건부 캡처\n",
    "def process_frame():\n",
    "    global frame, captured_frames\n",
    "    while True:\n",
    "        if frame is None:\n",
    "            continue\n",
    "\n",
    "        with lock:\n",
    "            img = frame.copy()\n",
    "\n",
    "        # YOLO Pose 모델 실행\n",
    "        results = model(img)\n",
    "        for result in results:\n",
    "            keypoints = result.keypoints.numpy() if result.keypoints is not None else []\n",
    "\n",
    "            # 키포인트 조건 확인 (머리, 팔, 다리 모두 감지 여부)\n",
    "            if check_keypoints_complete(keypoints):\n",
    "                # 조건 충족 시 캡처\n",
    "                with lock:\n",
    "                    captured_frames.append(img)\n",
    "\n",
    "# 키포인트 검증 함수\n",
    "def check_keypoints_complete(keypoints):\n",
    "    \"\"\"\n",
    "    특정 키포인트들이 모두 감지되었는지 확인.\n",
    "    - keypoints: [[x, y, confidence], ...] 형태의 배열\n",
    "    \"\"\"\n",
    "    for idx in KEYPOINTS_TO_CHECK:\n",
    "        if idx >= len(keypoints) or keypoints[idx][2] < 0.5:  # 키포인트 confidence < 0.5는 감지 실패로 간주\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
